{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.1\n"
     ]
    }
   ],
   "source": [
    "# https://www.drivendata.org/competitions/4/page/15/#sub_values\n",
    "# multi-class-multi-label classification problem, there are 9 broad categories that each take on many possible sub-label instances.\n",
    "# we are predicting probabilities of certain labels with the goal of grouping the items.\n",
    "# The submission must be 50064x104 where 50064 is the number of rows in the test dataset (excluding the header) and 104 is the number of columns (excluding a first column of row ids). The columns in the submission have the format ColumnName__PossibleLabel\n",
    "\n",
    "# Education Resource Strategies is a non-profit that tackles to solve budget problem with the goal of letting districts be smarter, more strategic, and more effective in their spending.\n",
    "# These labels let ERS understand how schools are spending money and tailor their strategy recommendations to improve outcomes for students, teachers, and administrators.\n",
    "\n",
    "from platform import python_version\n",
    "print(\"Python\", python_version())\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 25 columns):\n",
      "Function                  400277 non-null object\n",
      "Use                       400277 non-null object\n",
      "Sharing                   400277 non-null object\n",
      "Reporting                 400277 non-null object\n",
      "Student_Type              400277 non-null object\n",
      "Position_Type             400277 non-null object\n",
      "Object_Type               400277 non-null object\n",
      "Pre_K                     400277 non-null object\n",
      "Operating_Status          400277 non-null object\n",
      "Object_Description        375493 non-null object\n",
      "Text_2                    88217 non-null object\n",
      "SubFund_Description       306855 non-null object\n",
      "Job_Title_Description     292743 non-null object\n",
      "Text_3                    179964 non-null object\n",
      "Text_4                    53746 non-null object\n",
      "Sub_Object_Description    91603 non-null object\n",
      "Location_Description      162054 non-null object\n",
      "FTE                       126071 non-null float64\n",
      "Function_Description      342195 non-null object\n",
      "Facility_or_Department    53886 non-null object\n",
      "Position_Extra            264764 non-null object\n",
      "Total                     395722 non-null float64\n",
      "Program_Description       304660 non-null object\n",
      "Fund_Description          202877 non-null object\n",
      "Text_1                    292285 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 79.4+ MB\n",
      "None\n",
      "                       Function          Use          Sharing Reporting  \\\n",
      "134338     Teacher Compensation  Instruction  School Reported    School   \n",
      "206341                 NO_LABEL     NO_LABEL         NO_LABEL  NO_LABEL   \n",
      "326408     Teacher Compensation  Instruction  School Reported    School   \n",
      "364634  Substitute Compensation  Instruction  School Reported    School   \n",
      "47683   Substitute Compensation  Instruction  School Reported    School   \n",
      "\n",
      "       Student_Type Position_Type               Object_Type     Pre_K  \\\n",
      "134338     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
      "206341     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
      "326408  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
      "364634  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
      "47683   Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
      "\n",
      "         Operating_Status            Object_Description  \\\n",
      "134338  PreK-12 Operating                           NaN   \n",
      "206341      Non-Operating           CONTRACTOR SERVICES   \n",
      "326408  PreK-12 Operating  Personal Services - Teachers   \n",
      "364634  PreK-12 Operating             EMPLOYEE BENEFITS   \n",
      "47683   PreK-12 Operating  TEACHER COVERAGE FOR TEACHER   \n",
      "\n",
      "                    ...               Sub_Object_Description  \\\n",
      "134338              ...                                  NaN   \n",
      "206341              ...                                  NaN   \n",
      "326408              ...                                  NaN   \n",
      "364634              ...                                  NaN   \n",
      "47683               ...                                  NaN   \n",
      "\n",
      "       Location_Description  FTE     Function_Description  \\\n",
      "134338                  NaN  1.0                      NaN   \n",
      "206341                  NaN  NaN                 RGN  GOB   \n",
      "326408                  NaN  1.0                      NaN   \n",
      "364634                  NaN  NaN  UNALLOC BUDGETS/SCHOOLS   \n",
      "47683                   NaN  NaN              NON-PROJECT   \n",
      "\n",
      "       Facility_or_Department              Position_Extra      Total  \\\n",
      "134338                    NaN               KINDERGARTEN   50471.810   \n",
      "206341                    NaN                UNDESIGNATED   3477.860   \n",
      "326408                    NaN                     TEACHER  62237.130   \n",
      "364634                    NaN  PROFESSIONAL-INSTRUCTIONAL     22.300   \n",
      "47683                     NaN  PROFESSIONAL-INSTRUCTIONAL     54.166   \n",
      "\n",
      "                   Program_Description        Fund_Description  \\\n",
      "134338                    KINDERGARTEN            General Fund   \n",
      "206341   BUILDING IMPROVEMENT SERVICES                     NaN   \n",
      "326408           Instruction - Regular  General Purpose School   \n",
      "364634  GENERAL MIDDLE/JUNIOR HIGH SCH                     NaN   \n",
      "47683    GENERAL HIGH SCHOOL EDUCATION                     NaN   \n",
      "\n",
      "                               Text_1  \n",
      "134338                            NaN  \n",
      "206341  BUILDING IMPROVEMENT SERVICES  \n",
      "326408                            NaN  \n",
      "364634            REGULAR INSTRUCTION  \n",
      "47683             REGULAR INSTRUCTION  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "                 FTE         Total\n",
      "count  126071.000000  3.957220e+05\n",
      "mean        0.426794  1.310586e+04\n",
      "std         0.573576  3.682254e+05\n",
      "min        -0.087551 -8.746631e+07\n",
      "25%         0.000792  7.379770e+01\n",
      "50%         0.130927  4.612300e+02\n",
      "75%         1.000000  3.652662e+03\n",
      "max        46.800000  1.297000e+08\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# /home/radiance/Documents/datasets-7-7-17/ML_School_Budgets\n",
    "df = pd.read_csv(\"/home/radiance/Documents/datasets-7-7-17/ML_School_Budgets/TrainingSet.csv\", index_col=0) # 23 categories, 2 float\n",
    "print(df.info()) # feautures that cannot be identified = object\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAElCAYAAAAyWE/9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea0f86dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix this\n",
    "# histogram of the non-null 'FTE' column\n",
    "plt.hist(df['FTE'].dropna())\n",
    "plt.title(\"Distribution of %full-time \\n employee works\")\n",
    "plt.xlabel(\"% of full-time\")\n",
    "plt.ylabel(\"num of employees\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exploring datatypes in pandas\n",
    "#print(df.dtypes)\n",
    "#print(df.dtypes.value_counts()) # value_counts is Series method\n",
    "\n",
    "# There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take.\n",
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status'] \n",
    "#print(df[LABELS])\n",
    "#print(df[LABELS].dtypes) # object\n",
    "#print(type(df[LABELS])) # DataFrame\n",
    "\n",
    "# goal - predict the probability that a certain label is attached to a budget line item. \n",
    "# Encode the labels as categorical variables\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# .astype() only works on a pandas Series. Since you are working with a pandas DataFrame, you'll need to use the .apply() method and provide a lambda function called categorize_label that applies .astype() to each column, x.\n",
    "df[LABELS] = df[LABELS].apply(categorize_label)\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)\n",
    "\n",
    "#df.label = df[[label]].apply(categorize_label, axis=0) # [[]] - dataframe\n",
    "#df['Function'] = df['Function'].astype('category')\n",
    "#df['Function'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFjCAYAAAAw4gyuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwMysyzkRmJl1OScCM7Mu9/+jydUFk/PlMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea0f9641d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Counting unique labels\n",
    "# there are over 100 unique labels. count and plotting the number of unique values for each category of label.\n",
    "df['Function'].unique()\n",
    "df['Use'].unique()\n",
    "\n",
    "# pandas - use pd.Series.nunique method for counting the number of unique values in a Series.\n",
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_values = df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "# Create a bar plot of num_unique_labels\n",
    "num_unique_values.plot(kind='bar')\n",
    "plt.title(\"Distribution of unique values for each category\")\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing log loss with NumPy\n",
    "def compute_log_loss(predicted,actual, eps=1e-14):\n",
    "    logloss = -1 * np.mean(actual*np.log(predicted) + (1-actual)*np.log(1-predicted))\n",
    "    return logloss\n",
    "\n",
    "#Log loss penalizes highly confident wrong answers much more than any other type. This will be a good metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      320222 non-null float64\n",
      "Total    320222 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Data columns (total 2 columns):\n",
      "FTE      80055 non-null float64\n",
      "Total    80055 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. use the function to make sure the least min_count examples of each label appear in each split: multilabel_train_test_split.\n",
    "# Building Simple model with just the numeric columns of your DataFrame\n",
    "\n",
    "NUMERIC_COLUMNS = ['FTE','Total']\n",
    "#df[NUMERIC_COLUMNS]\n",
    "\n",
    "# Create the new DataFrame: numeric_data_only\n",
    "# We are replacing -1000 with NAN so as to differentiate from 0\n",
    "numeric_data_only = pd.DataFrame(df[NUMERIC_COLUMNS]).fillna(-1000)\n",
    "\n",
    "# Dummy variable encoding - binary indicator representation\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS], prefix_sep=\"_\")\n",
    "\n",
    "import sys\n",
    "# the ML_School_Budgets contains multilabel.py\n",
    "sys.path.append('/home/radiance/Documents/datasets-7-7-17/ML_School_Budgets')\n",
    "\n",
    "# Import multilabel_train_test_split from /home/radiance/Documents/datasets-7-7-17/ML_School_Budgets/multilabel.py\n",
    "from multilabel import multilabel_train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Training a model\n",
    "# as we're throwing away all of the text data in the dataset - that's by far most of the data! So no killer performance.\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "# The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training classifier\n",
      "Time taken to train classifier: 0:05:29.860768\n"
     ]
    }
   ],
   "source": [
    "# Use your model to predict values on holdout data\n",
    "# The original goal is to predict the probability of each label. use the .predict_proba() method on your trained model.\n",
    "# from time import time\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "start = time()\n",
    "print(\"Started training classifier\")\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Time taken to train classifier: {}\".format(timedelta(seconds=time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']\n"
     ]
    }
   ],
   "source": [
    "# Creating a bag-of-words in scikit-learn\n",
    "# focus on one feature Position_Extra column, which describes any additional information not captured by the Position_Type label like df.loc[8960]\n",
    "# Position_Extra has lots of NaN\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])\n",
    "# Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens. You've got bag-of-words in the bag!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining text columns for tokenization\n",
    "# CountVectorizer expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\n",
    "# this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method.\n",
    "\n",
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4758 tokens in the dataset\n",
      "There are 3284 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Now you will use combine_text_columns to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method.\n",
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "# this regex splits on whitespace\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "# Fit parses the data and creates a vocabulary, while Transform tokenize text and produce an array of counts\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using FunctionTransformer on the main dataset\n",
    "# using FunctionTransformer on the primary budget data, before instantiating a multiple-datatype pipeline\n",
    "# custom function combine_text_columns to select and properly format text data for tokenization\n",
    "# Concerning the numeric data, you can use NUMERIC_COLUMNS, preloaded as usual, to help design a subset-selecting lambda function.\n",
    "\n",
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training classifier\n",
      "Time taken to train classifier: 0:15:11.268339\n",
      "\n",
      "Accuracy on budget dataset:  0.351258509775\n"
     ]
    }
   ],
   "source": [
    "# Add a model to the pipeline\n",
    "# The structure of the pipeline\n",
    "# the preprocessing step uses FeatureUnion to join the results of nested pipelines that each rely on FunctionTransformer to select multiple datatypes\n",
    "# the model step stores the model object\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector',get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "print(\"Started training classifier\")\n",
    "# Fit it to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "print(\"Time taken to train classifier: {}\".format(timedelta(seconds=time() - start)))\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training classifier\n",
      "Time taken to train classifier: 0:06:50.485994\n",
      "\n",
      "Accuracy on budget dataset:  0.912759977515\n"
     ]
    }
   ],
   "source": [
    "# adjusting the model or parameters to improve accuracy?\n",
    "# Updating the parameters n_estimators of RandomForestClassifier(), whose default value is 10, to 15.\n",
    "\n",
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15))\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "print(\"Started training classifier\")\n",
    "# Fit it to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "print(\"Time taken to train classifier: {}\".format(timedelta(seconds=time() - start)))\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n",
    "# It's time to get serious and work with the log loss metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fiting text_vector...\n",
      "Total time taken to train text_vector: 0:00:07.429016\n",
      "['00a', '12', '1st', '2nd', '3rd', '4th', '5', '56', '5th', '6']\n"
     ]
    }
   ],
   "source": [
    "# Using CountVectorizer on the training data X_train to see the effect of tokenization on punctuation. Remember, since CountVectorizer expects a vector, combine_text_columns before fitting to the training data.\n",
    "# Importing the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate the CountVectorizer: text_features\n",
    "text_features = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "start = time()\n",
    "print(\"Started fiting text_vector...\")\n",
    "# Fit text_features to the text vector\n",
    "text_features.fit(text_vector)\n",
    "print(\"Total time taken to train text_vector: {}\".format(timedelta(seconds=time() - start)))\n",
    "\n",
    "# Print the first 10 tokens\n",
    "print(text_features.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training classifier\n",
      "Time taken to train classifier: 0:07:32.167802\n"
     ]
    }
   ],
   "source": [
    "# N-gram range - look for ngram relationships at multiple scales, you will use the ngram_range parameter - 1,2\n",
    "# Adding dim_red step & scale step\n",
    "# Apply dimensionality reduction technique - dim_red step. we have to scale the features to lie between -1 and 1 using scale step.\n",
    "# The dim_red step uses SelectKBest(), applying chi-squared test to select the K \"best\" features. The scale step uses MaxAbsScaler() in order to squash the relevant features into the interval -1 to 1.\n",
    "\n",
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "print(\"Started training classifier\")\n",
    "# Fit it to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "print(\"Time taken to train classifier: {}\".format(timedelta(seconds=time() - start)))\n",
    "\n",
    "# Log loss score: 1.2681."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric_features', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x7fe9fa912730>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='dep...=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interaction modeling with SparseInteractions - Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row.\n",
    "# considering interaction terms of degree=2\n",
    "# interaction terms - take long to train - making n features into n-squared features\n",
    "\n",
    "from SparseInteractions import SparseInteractions\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),  \n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "print(\"Started training classifier\")\n",
    "# Fit it to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "# Log loss score: 1.2256. Nice improvement from 1.2681!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.787508587846\n"
     ]
    }
   ],
   "source": [
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radiance/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/radiance/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  2.0\n",
      "3  1.0\n",
      "4  1.0\n"
     ]
    }
   ],
   "source": [
    "# using hashing trick?\n",
    "# a hash function takes an input, in your case a token, and outputs a hash value. For example, the input may be a string and the hash value may be an integer.\n",
    "# Enforcing a fixed length can speed up calculations drastically, especially on large datasets!\n",
    "# Hashing vectorizer is very low memory scalable to large datasets as there is no need to store a vocabulary dictionary in memory,   it is fast to pickle and un-pickle as it holds no state besides the constructor parameters, it can be used in a streaming (partial fit) or parallel pipeline as there is no state computed during fit.\n",
    "\n",
    "# Implementing the hashing trick in scikit-learn\n",
    "# HashingVectorizer acts just like CountVectorizer in that it can accept token_pattern and ngram_range parameters. The important difference is that it creates hash values from the text, so that we get all the computational advantages of hashing!\n",
    "\n",
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(norm=None,non_negative=True,token_pattern=TOKENS_ALPHANUMERIC,ngram_range=(1,2))\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radiance/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/radiance/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Final model\n",
    "# add the HashingVectorizer step to the pipeline to replace the CountVectorizer step.\n",
    "\n",
    "# Import the hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "print(\"Started training classifier\")\n",
    "# Fit it to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "print(\"Time taken to train classifier: {}\".format(timedelta(seconds=time() - start)))\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
